 # -*- coding: utf-8 -*-
"""
Twitter Analysis: CNN Model (Convolutional Neural Network)
@author: Maxfield England

Given the twitter data generated by get_tweets.py,
learns tweet sentiment by baseline generated from VADER and
predicts additional tweets based on the model.
"""

#from nltk.corpus import stopwords
#from collections import Counter
import pickle
from numpy import array
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils.vis_utils import plot_model
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Embedding
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from collections import Counter
from matplotlib import pyplot
from pandas import DataFrame

#load doc; returns text read from document
def load_doc(filename):
    file = open(filename, 'r')
    text = file.read()
    file.close()
    return text


def save_list(lines, filename):
    #make single text body: each word on a separate line
    data = '\n'.join(lines)
    file = open(filename, 'w')
    file.write(data)
    file.close()
    


#fit a tokenizer
def create_tokenizer(lines):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(lines)
    return tokenizer

#integer encode and pad documents
def encode_docs(tokenizer, max_length, docs):
    encoded = tokenizer.texts_to_sequences(docs)
    #pad em!
    padded = pad_sequences(encoded, maxlen=max_length, padding='post')
    return padded

def define_model(vocab_size, max_length):
    model = Sequential()
    model.add(Embedding(vocab_size, 100, input_length=max_length))
    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    #compile network
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    #summarize
    model.summary()
    plot_model(model, to_file='modelCNN.png', show_shapes=True)
    return model


#---------------------------------
#Get corpora from files
#---------------------------------
#Get training and testing corpora (tweet arrays): pre-cleaned
training = []
testing = []
trainingRaw = []
testingRaw = []
with open('training.corpus', 'rb') as trainReadFile:
    training = pickle.load(trainReadFile)
with open('testing.corpus', 'rb') as testReadFile:
    testing = pickle.load(testReadFile)
    
    
#Retrieve raw tweets (tweet arrays): non-cleaned
with open('training.raw', 'rb') as trainRawReadFile:
    trainingRaw = pickle.load(trainRawReadFile)

with open('testing.raw', 'rb') as testRawReadFile:
    testingRaw = pickle.load(testRawReadFile)    

#----------------------------------------
#Restrict vocabulary
#----------------------------------------    
#Create vocabulary using a counter for every tweet in the training corpus
vocab = Counter()

for tweet in training:
    words = tweet.split()
    vocab.update(words)


#Filter out vocab words that don't appear at least twice
min_occurrence = 2
vocab_reduced = [k for k,c in vocab.items() if c >= min_occurrence]

#Filter words not found in vocab
for tweet in training:
    words = tweet.split()
    words = [w for w in words if w in vocab_reduced]
    tweet = " ".join(words)

#--------------------------------------
# Collect VADER-assigned sentiments as our control for training values
# and use these for testing purposes (we're essentially teaching our model
# to mimic VADER here, huh?)
#--------------------------------------

#Using the raw tweets and VADER, assign positive/negative scores (ytrain/ytest)
#for learning and testing purposes
sen = SentimentIntensityAnalyzer()
ytrvals = []
for tweet in trainingRaw:
    tweetScore = sen.polarity_scores(tweet)['compound']
    #Adjust (-1, 1) score to be applicable for range (0, 1)
    tweetScore = (tweetScore+1)/2
    
    #DEBUG:
    if tweetScore >= 0.5:
        tweetScore = 1
    else:
        tweetScore = 0
    
    ytrvals.append(tweetScore)
    
ytrain = array(ytrvals)

ytevals = []
for tweet in testingRaw:
    tweetScore = sen.polarity_scores(tweet)['compound']
        #Adjust (-1, 1) score to be applicable for range (0, 1)
    tweetScore = (tweetScore+1)/2
    
    #Model only works for binary 
    if tweetScore >= 0.5:
        tweetScore = 1
    else:
        tweetScore = 0
    
    ytevals.append(tweetScore)
ytest = array(ytevals)


#-------------------------------------
# Create model
#-------------------------------------
tokenizer = create_tokenizer(training)
vocab_size = len(tokenizer.word_index) + 1

# print("Vocabulary size: %d" % vocab_size)
#calculate max sequence length
max_length = max([len(s.split()) for s in training])
print('Maximum length: %d' % max_length)
Xtrain = encode_docs(tokenizer, max_length, training)
Xtest = encode_docs(tokenizer, max_length, testing)

#define model
model = define_model(vocab_size, max_length)
#load model
#model = load_model('model1.h5')

model.fit(Xtrain, ytrain, epochs=10, verbose=2)


#-------------------------------------
#Evaluate model
#-------------------------------------
_, acc = model.evaluate(Xtrain, ytrain, verbose=0)
print("Train Accuracy: %.2f" % (acc*100))
_, acc = model.evaluate(Xtest, ytest, verbose=0)
print("Test accuracy: %.2f" % (acc*100))


# Generate data of model evaluations of tweets
numPos = 0
numNeg = 0
numNeutral = 0

for tweet in testing:
    
    padded = encode_docs(tokenizer, max_length, [tweet])
    yhat = model.predict(padded, verbose=0)
    percent_pos = yhat[0,0]
    
    if percent_pos < 0.45:
        numNeg+=1
    elif percent_pos > 0.55:
        numPos+=1
    else: 
        numNeutral+=1

print("Convolutional Neural Network:")
print("Number of tweets that are positive:",numPos)
print("Number of tweets that are negative:",numNeg)
print("Number of tweets that are neutral:", numNeutral)


